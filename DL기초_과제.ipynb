{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "DL기초 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkosmi/ybigta/blob/master/DL%EA%B8%B0%EC%B4%88_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lTEIANOIyQa"
      },
      "source": [
        "# 과제1: tensorflow를 이용한 NN 밑바닥부터 구현\n",
        "input feature가 100개이고,  \n",
        "hidden layer가 2개이고 neuron이 각각 50,10개이고,  \n",
        "output이 5개인 NN를 구현해 보자  \n",
        "* hidden layer는 relu를 activation function으로, output layer는 softmax를 activation function으로 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGB9wOSEIyQf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsUKFHuQIyQg"
      },
      "source": [
        "n_x = 100\n",
        "n_h1 = 50\n",
        "n_h2 = 10\n",
        "n_y = 5"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk9YtbcmIyQh",
        "outputId": "af368e06-d262-479f-ed2d-63e598944827"
      },
      "source": [
        "# Simulate train set\n",
        "m = 500\n",
        "\n",
        "x_train=np.random.randn(m,n_x).astype(np.float32)\n",
        "y_train=np.zeros((m,n_y)).astype(np.float32)\n",
        "y_train[np.arange(m),np.random.randint(n_y,size=m)]=1\n",
        "\n",
        "print(x_train)\n",
        "print(y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.4148176  -0.12811758  2.1195862  ... -0.79631376 -0.80298257\n",
            "  -0.23154707]\n",
            " [ 0.2650589  -0.5807347  -0.37117913 ... -0.7096159   0.08810216\n",
            "  -0.5848298 ]\n",
            " [-0.66165787 -0.5598481   0.9231691  ...  1.4476304  -0.96571434\n",
            "   0.38199127]\n",
            " ...\n",
            " [-0.64469165 -0.39725477 -0.4246492  ...  0.54368275 -1.0609186\n",
            "   0.9549599 ]\n",
            " [ 0.48217833 -0.9190567   0.5009376  ...  1.4610416  -0.33776233\n",
            "  -0.5260377 ]\n",
            " [ 0.99762315 -0.72476274 -0.57272995 ...  0.7682012  -2.3565116\n",
            "  -0.5821261 ]]\n",
            "[[0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JYIozUuIyQh"
      },
      "source": [
        "* Initialization of weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBeYQHPLIyQi"
      },
      "source": [
        "w1=tf.Variable(1e-3*np.random.randn(n_x,n_h1).astype(np.float32),name=\"w1\")\n",
        "## 코드를 작성해 보세요 ## \n",
        "w2=tf.Variable(1e-3*np.random.randn(n_h1,n_h2).astype(np.float32),name=\"w2\")\n",
        "w3=tf.Variable(1e-3*np.random.randn(n_h2,n_y).astype(np.float32),name=\"w3\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84Lg7yVYIyQi"
      },
      "source": [
        "* forward propagation을 통해 prediction 값을 구하고, loss를 구하는 function을 만들어 봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4a8w-dSIyQj"
      },
      "source": [
        "def forward(x):\n",
        "    z1=tf.matmul(x,w1)\n",
        "    a1=tf.nn.relu(z1)\n",
        "    ## 코드를 작성해 보세요 ##\n",
        "    z2=tf.matmul(a1,w2)\n",
        "    a2=tf.nn.relu(z2)\n",
        "    z3=tf.matmul(a2,w3)\n",
        "    predictions = tf.nn.softmax(z3)\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def loss_fn(predictions, y):\n",
        "    loss= -tf.reduce_sum(y*tf.math.log(predictions))\n",
        "    return loss    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9oUsDTpIyQj"
      },
      "source": [
        "* backpropagation & update parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjVIN0-NIyQj"
      },
      "source": [
        "learning_rate=1e-2\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = forward(x)\n",
        "        loss = loss_fn(predictions, y)\n",
        "    ## 코드를 작성해 보세요 ## (hint: tape.gradient를 구글링 해보세요)\n",
        "    gradient = tape.gradient(loss, [w1,w2,w3])\n",
        "    # optimizer와 위에서 구한 경사도를 이용해 가중치들을 업데이트 합니다.\n",
        "    optimizer.apply_gradients(zip(gradient, [w1, w2, w3]))\n",
        "    return loss, w1, w2, w3\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9_C33UMIyQk"
      },
      "source": [
        "* 간단하게 train loop를 작성해 loss가 줄어나가는지 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu4hemsWIyQk",
        "outputId": "91b73dd6-0c5b-46ec-e623-f2e7bf308681"
      },
      "source": [
        "loss_list = []\n",
        "\n",
        "for step in range(10): \n",
        "    loss, w1, w2, w3 = train_step(x_train, y_train)\n",
        "    loss_list.append(loss.numpy())\n",
        "    \n",
        "print(loss_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[804.7187, 804.70416, 804.46796, 803.6229, 801.5674, 797.6154, 791.1305, 781.83636, 770.31903, 758.35394]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-u32UXdIyQk"
      },
      "source": [
        "# 과제2: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
        "\n",
        "\n",
        "## Loading MNIST training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grADQX75IyQk",
        "outputId": "bd974953-cf3e-45d1-f0c3-3b7adc67cbbb"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scaling(image data는 min-max scaling 주로 사용)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGW4UXZGIyQl"
      },
      "source": [
        "## Training Data\n",
        "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-yzw45ZIyQl",
        "outputId": "eb7c976c-52fa-46e1-f313-1f218c237003"
      },
      "source": [
        "x_train.shape "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4lERkxDIyQl"
      },
      "source": [
        "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
        "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iadQCTRIyQl"
      },
      "source": [
        "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOrPcdrGIyQl"
      },
      "source": [
        "plt.imshow(x_train[0]).set_cmap('Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeNTaZpXIyQl"
      },
      "source": [
        "## Training Labels\n",
        "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
        "마찬가지로, 60000개의 label이 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXWIBN6BIyQm",
        "outputId": "91eb0c5a-3c31-4acb-f83d-3abb408b2181"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpgI-30uIyQm",
        "outputId": "3d74f207-cb87-4ccd-f373-3de8aea72366"
      },
      "source": [
        "# show MNIST label for above data\n",
        "y_train[4]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSoR9HfgIyQm"
      },
      "source": [
        "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbTVAYP8IyQm"
      },
      "source": [
        "* parameters for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6ypjskIyQm"
      },
      "source": [
        "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
        "\n",
        "loss_list = [\"sparse_categorical_crossentropy\",\n",
        "             \"categorical_crossentropy\", \n",
        "             \"binary_crossentropy\"]\n",
        "\n",
        "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
        "\n",
        "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
        "                    tf.keras.initializers.RandomUniform(), \n",
        "                    tf.keras.initializers.he_normal(), \n",
        "                    tf.keras.initializers.he_uniform(), \n",
        "                    tf.keras.initializers.GlorotUniform(),\n",
        "                    tf.keras.initializers.GlorotNormal()]\n",
        "\n",
        "# dropout\n",
        "dropout_rate = 0.3\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dropout(dropout_rate)\n",
        "])\n",
        "\n",
        "\n",
        "# regularizer\n",
        "regularizer = tf.keras.regularizers.l1(1e-3)\n",
        "regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          activity_regularizer=regularizer)\n",
        "])\n",
        "\n",
        "# weight initialization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          kernel_initializer=initializer_list[0])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNrtFZvXIyQm"
      },
      "source": [
        "#### My Own Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfLSGsAyIyQn"
      },
      "source": [
        "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
        "model = keras.Sequential([\n",
        "            keras.layers.Dense(784, kernel_initializer='he_normal', activity_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
        "            keras.layers.Dense(128, activation = 'relu', kernel_initializer='he_normal', activity_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
        "            keras.layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uk7LS3ZNgtL"
      },
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", \r\n",
        "              optimizer = \"adam\", \r\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGLedqOyIyQn"
      },
      "source": [
        "내가 만든 모델을 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clb_CncDIyQn",
        "outputId": "574d24fd-1406-4acb-f468-9df5fc92afa5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (32, 784)                 615440    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (32, 128)                 100480    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (32, 10)                  1290      \n",
            "=================================================================\n",
            "Total params: 717,210\n",
            "Trainable params: 717,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKwNgY8SIyQn",
        "outputId": "0d5d0aca-3c07-4b95-be6f-43f5e2263937"
      },
      "source": [
        "history = model.fit(x_train, y_train,  epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3157 - accuracy: 0.9564\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2880 - accuracy: 0.9615\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2673 - accuracy: 0.9640\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2631 - accuracy: 0.9648\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2410 - accuracy: 0.9688\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2374 - accuracy: 0.9686\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2334 - accuracy: 0.9699\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2185 - accuracy: 0.9720\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2239 - accuracy: 0.9706\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2087 - accuracy: 0.9744\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2051 - accuracy: 0.9743\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2068 - accuracy: 0.9752\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2089 - accuracy: 0.9735\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1980 - accuracy: 0.9768\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2007 - accuracy: 0.9755\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1947 - accuracy: 0.9773\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1939 - accuracy: 0.9778\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1900 - accuracy: 0.9788\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1888 - accuracy: 0.9782\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1930 - accuracy: 0.9771\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1925 - accuracy: 0.9782\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1914 - accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1876 - accuracy: 0.9785\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1826 - accuracy: 0.9789\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1879 - accuracy: 0.9789\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1705 - accuracy: 0.9821\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1855 - accuracy: 0.9786\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1796 - accuracy: 0.9807\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1806 - accuracy: 0.9803\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1819 - accuracy: 0.9800\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1710 - accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1798 - accuracy: 0.9805\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1775 - accuracy: 0.9808\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1714 - accuracy: 0.9818\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1827 - accuracy: 0.9801\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1758 - accuracy: 0.9815\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1809 - accuracy: 0.9810\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1713 - accuracy: 0.9823\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1765 - accuracy: 0.9816\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1690 - accuracy: 0.9826\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1696 - accuracy: 0.9826\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1695 - accuracy: 0.9833\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1713 - accuracy: 0.9828\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1827 - accuracy: 0.9807\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1658 - accuracy: 0.9833\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1805 - accuracy: 0.9814\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1646 - accuracy: 0.9830\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1685 - accuracy: 0.9829\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1721 - accuracy: 0.9831\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1607 - accuracy: 0.9847\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1792 - accuracy: 0.9816\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1669 - accuracy: 0.9837\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1729 - accuracy: 0.9832\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1726 - accuracy: 0.9826\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1709 - accuracy: 0.9837\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1692 - accuracy: 0.9835\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1674 - accuracy: 0.9840\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1703 - accuracy: 0.9833\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1672 - accuracy: 0.9840\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1785 - accuracy: 0.9826\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1633 - accuracy: 0.9848\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1653 - accuracy: 0.9843\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1755 - accuracy: 0.9830\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1714 - accuracy: 0.9835\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1690 - accuracy: 0.9840\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1749 - accuracy: 0.9840\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1617 - accuracy: 0.9850\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1705 - accuracy: 0.9841\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1623 - accuracy: 0.9851\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1642 - accuracy: 0.9853\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1751 - accuracy: 0.9826\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1656 - accuracy: 0.9844\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1747 - accuracy: 0.9830\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1568 - accuracy: 0.9862\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1922 - accuracy: 0.9799\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1512 - accuracy: 0.9874\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1700 - accuracy: 0.9844\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1755 - accuracy: 0.9835\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1658 - accuracy: 0.9846\n",
            "Epoch 80/100\n",
            "1021/1875 [===============>..............] - ETA: 4s - loss: 0.1473 - accuracy: 0.9878"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wWepriUIyQn"
      },
      "source": [
        "model을 자유롭게 train 해봅시다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld_HbhTbIyQn"
      },
      "source": [
        "95%이상의 성능을 가진 모델을 만들면 완성!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjOyEhYFIyQn",
        "outputId": "eff5fcb5-a19f-4518-8956-42203934c1a3"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
        "\n",
        "print('\\nAccuracy:', test_acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.3216 - accuracy: 0.9631\n",
            "\n",
            "Accuracy: 0.963100016117096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "hm1qZTBbIyQo"
      },
      "source": [
        "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
      ]
    }
  ]
}